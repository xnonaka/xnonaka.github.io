[
  {
    "objectID": "waterinsecurity.html",
    "href": "waterinsecurity.html",
    "title": "Water Insecurity in the US (2023)",
    "section": "",
    "text": "Water Insecurity in US Counties\nThis dataset contains the percentage of people lacking plumbing in US counties. To create a simpler plot, I took the mean percentages across each state’s counties, and displayed that value (each point is a state).\n\n\n\n\n\n\n\n\n\nThis graph plots the mean percentage of population lacking plumbing for each state across its counties. The states are grouped into the U.S. census regions (with Puerto Rico added to the South region), to compare mean county percentages in each region.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNULL\n\n\nSources: Azadpour, Elmera and Nell, Cee, 2024, “Mapping water insecurity in R with tidycensus,” USGS,https://waterdata.usgs.gov/blog/acs-maps/\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-01-28 USGS - https://waterdata.usgs.gov/blog/acs-maps/\nU.S. Census Bureau, 2023, “Tenure by Plumbing Facilities,” American Community Survey, 1-Year Estimates Detailed Tables, Table B25049, accessed on Nov 27, 2024, https://data.census.gov/table?q=B25049&y=2023 .\nU.S. Census Bureau, 2023, “Total Population,” American Community Survey, 1-Year Estimates Detailed Tables, Table B01003, accessed on Nov 27, 2024, https://data.census.gov/table?q=B01003&y=2023 .\nU.S. Census Bureau, 2025, “County Population by Characteristics: 2020-2024”, Annual County Resident Population Estimates by Age, Sex, Race, and Hispanic Origin: April 1, 2020 to July 1, 2024, accessed on Dec 2, 2025, https://www.census.gov/data/tables/time-series/demo/popest/2020s-counties-detail.html"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xander Nonaka",
    "section": "",
    "text": "Hi! My name is Xander, I’m a senior at Pomona College from San Francisco, CA. I spent most of my childhood in SF, but also lived in Tokyo, Japan for five years. The photo here is one I took of the redwood trees at Muir Woods, north of San Francisco. Exploring California’s natural features sparked my interest in the environment, which motivated me to study environmental policy at Pomona. I’m also passionate about sports and music, and spend my time watching Bay Area sports and taking music lessons."
  },
  {
    "objectID": "traffic.html",
    "href": "traffic.html",
    "title": "Daily England Traffic",
    "section": "",
    "text": "England National Highways Traffic Data Set\nThe data set used in this plot contains speed and vehicle volume data captured throughout the day over the course of many days on different highway sites in England.\n\n\n\n\n\n\n\n\n\nAverage speed across all highway sites is measured relative to the time of day the data was captured. Time is displayed here as a series of interval numbers from 0 to 95. 0 represents the first period of data on a new day, and 95 represents the last. Thus noon is around the 47th interval.\nSource: https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-12-03/readme.md National Highways - https://webtris.nationalhighways.co.uk/api/swagger/ui/index"
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Analyses of Text from Shakespeare’s Plays",
    "section": "",
    "text": "Code\nhamlet_words &lt;- hamlet %&gt;% \n  mutate(\n    light_words = str_count(dialogue, \"\\\\b(light|sun|day)\\\\b\"),\n    dark_words = str_count(dialogue, \"\\\\b(dark|black|night)\\\\b\")\n  ) %&gt;% \n  summarize(\n    light = sum(light_words),\n    dark = sum(dark_words)\n  )\n\nmacbeth_words &lt;- macbeth %&gt;% \n  mutate(\n    light_words = str_count(dialogue, \"\\\\b(light|sun|day)\\\\b\"),\n    dark_words = str_count(dialogue, \"\\\\b(dark|black|night)\\\\b\")\n  ) %&gt;% \n  summarize(\n    light = sum(light_words),\n    dark = sum(dark_words)\n  )\n\nromeo_juliet_words &lt;- romeo_juliet %&gt;% \n  mutate(\n    light_words = str_count(dialogue, \"\\\\b(light|sun|day)\\\\b\"),\n    dark_words = str_count(dialogue, \"\\\\b(dark|black|night)\\\\b\")\n  ) %&gt;% \n  summarize(\n    light = sum(light_words),\n    dark = sum(dark_words)\n  )\n\n\n\n\nCode\nlight_dark_words &lt;- data_frame(play = c(\"Hamlet\", \"Macbeth\", \"Romeo and Juliet\"), \n                               light = c(hamlet_words$light, macbeth_words$light, romeo_juliet_words$light), \n                               dark = c(hamlet_words$dark, macbeth_words$dark, romeo_juliet_words$dark))\nlight_dark_words &lt;- pivot_longer(light_dark_words, cols=c(light, dark), names_to=\"word type\", values_to=\"count\")\n\n\n\n\nCode\nggplot(light_dark_words, aes(\n  x=play, \n  y=count, \n  fill=`word type`\n)) +\n  geom_col() +\n  labs(x=\"Play\",\n       y=\"Word Count\")\n\n\n\n\n\n\n\n\n\nEach word type contains three words (dark has “dark”, “black”, and “night”, and light has “light”, “sun”, and “day”). These are very limited categories for such broad themes, but how often these word types occur in each play. Romeo and Juliet twice as many of these words as the other two plays (even though Hamlet has the most words total). This may reflect the kinds of imagery used in Romeo and Juliet, in which the light and dark types are split about evenly. Hamlet and Macbeth have slightly more dark words, which may illustrate the darker settings/vibes of these plays (even though they are all tragedies).\n\n\nCode\nwords_following_I &lt;- hamlet %&gt;%\n  mutate(\n    following_I = str_extract(dialogue,\"(?&lt;=\\\\bI\\\\s)\\\\w+\")\n  )\n  \n#words_following_I\n\n\n\n\nCode\nI_words &lt;- words_following_I %&gt;% \n  filter(!is.na(following_I)) %&gt;% \n  group_by(following_I) %&gt;% \n  summarize(count = n()) %&gt;% \n  arrange(desc(count))\n\n\nhead(I_words, 20)\n\n\n# A tibble: 20 × 2\n   following_I count\n   &lt;chr&gt;       &lt;int&gt;\n 1 have           48\n 2 am             43\n 3 will           43\n 4 do             31\n 5 know           19\n 6 pray           17\n 7 would          14\n 8 shall          12\n 9 had            11\n10 did            10\n11 must           10\n12 think          10\n13 cannot          8\n14 could           7\n15 saw             7\n16 see             7\n17 hope            5\n18 mean            5\n19 was             5\n20 can             4\n\n\nThis table shows the most common words following “I” in Hamlet. My goal was to idenfity the most common verbs from the play, and see if any uncommon or unexpected ones occur often. Shakespeare obviously used many words that are not widely used or understood anymore, but all of the most common verbs were very standard to today’s English. One drawback from my code is I was only able to extract the words following the first “I” in a single line (so if I was used twice, it didn’t extract the next word to add to the count).\n\n\nCode\nopposite_words_romeo_juliet &lt;- romeo_juliet %&gt;% \n  mutate(\n    w_love = str_detect(dialogue, \"\\\\blove\\\\b\"),\n    w_hate = str_detect(dialogue, \"\\\\bhate\\\\b\"),\n    w_life = str_detect(dialogue, \"\\\\blife\\\\b\"),\n    w_death = str_detect(dialogue, \"\\\\bdeath\\\\b\"),\n    w_heaven = str_detect(dialogue, \"\\\\bheaven\\\\b\"), \n    w_hell = str_detect(dialogue, \"\\\\bhell\\\\b\")\n  ) \nsum_words_romeo_juliet &lt;-opposite_words_romeo_juliet %&gt;% \n  summarize(\n    love = sum(w_love), \n    hate = sum(w_hate), \n    life = sum(w_life), \n    death = sum(w_death), \n    heaven = sum(w_heaven),\n    hell = sum(w_hell)\n  )\n\nopposite_words_hamlet &lt;- hamlet %&gt;% \n  mutate(\n    w_love = str_detect(dialogue, \"\\\\blove\\\\b\"),\n    w_hate = str_detect(dialogue, \"\\\\bhate\\\\b\"),\n    w_life = str_detect(dialogue, \"\\\\blife\\\\b\"),\n    w_death = str_detect(dialogue, \"\\\\bdeath\\\\b\"),\n    w_heaven = str_detect(dialogue, \"\\\\bheaven\\\\b\"), \n    w_hell = str_detect(dialogue, \"\\\\bhell\\\\b\")\n  ) \nsum_words_hamlet &lt;-opposite_words_hamlet %&gt;% \n  summarize(\n    love = sum(w_love), \n    hate = sum(w_hate), \n    life = sum(w_life), \n    death = sum(w_death), \n    heaven = sum(w_heaven),\n    hell = sum(w_hell)\n  )\n\nopposite_words_macbeth &lt;- macbeth %&gt;% \n  mutate(\n    w_love = str_detect(dialogue, \"\\\\blove\\\\b\"),\n    w_hate = str_detect(dialogue, \"\\\\bhate\\\\b\"),\n    w_life = str_detect(dialogue, \"\\\\blife\\\\b\"),\n    w_death = str_detect(dialogue, \"\\\\bdeath\\\\b\"),\n    w_heaven = str_detect(dialogue, \"\\\\bheaven\\\\b\"), \n    w_hell = str_detect(dialogue, \"\\\\bhell\\\\b\")\n  ) \nsum_words_macbeth &lt;-opposite_words_macbeth %&gt;% \n  summarize(\n    love = sum(w_love), \n    hate = sum(w_hate), \n    life = sum(w_life), \n    death = sum(w_death), \n    heaven = sum(w_heaven),\n    hell = sum(w_hell)\n  )\n\n\n\n\nCode\nromeo_juliet_df &lt;-pivot_longer(sum_words_romeo_juliet, cols=everything(), names_to = \"word\", values_to = \"count\")\nhamlet_df &lt;- pivot_longer(sum_words_hamlet, cols=everything(), names_to = \"word\", values_to = \"count\")\nmacbeth_df &lt;- pivot_longer(sum_words_macbeth, cols=everything(), names_to = \"word\", values_to = \"count\")\n\n\n\n\nCode\nromeo_juliet_df$word &lt;- factor(romeo_juliet_df$word, levels = c(\"love\", \"hate\", \"life\", \"death\", \"heaven\", \"hell\"))\nhamlet_df$word &lt;- factor(hamlet_df$word, levels = c(\"love\", \"hate\", \"life\", \"death\", \"heaven\", \"hell\"))\nmacbeth_df$word &lt;- factor(macbeth_df$word, levels = c(\"love\", \"hate\", \"life\", \"death\", \"heaven\", \"hell\"))\n\n\n\n\nCode\nggplot(romeo_juliet_df, aes(x=word, y=count)) + \n  geom_col() +\n  labs(x=\"Word\", \n       y=\"Count\",\n       title=\"Word counts in Romeo and Juliet\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(hamlet_df, aes(x=word, y=count)) + \n  geom_col() +\n  labs(x=\"Word\", \n       y=\"Count\",\n       title=\"Word counts in Hamlet\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(macbeth_df, aes(x=word, y=count)) + \n  geom_col() +\n  labs(x=\"Word\", \n       y=\"Count\",\n       title=\"Word counts in Macbeth\")\n\n\n\n\n\n\n\n\n\nI wanted to expand on the first plot’s theme of opposite word frequency. I identified three word pairs to count using the detect function, and plotted the distribution for all three plays. The highest total for any word is “love” in Romeo and Juliet, which makes sense. The play also favors “death” to “life” much more heavily than the other two plays. Life and death are split equally in Macbeth (and both slightly higher than “love”). “Hate” doesn’t seem to be as common a word for Shakespeare.\nSources: TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-09-17/readme.md\nData: Massachussetts Institute of Technology, “The Complete Works of William Shakespeare” https://shakespeare.mit.edu/\nShakespeare, “Hamlet” https://shakespeare.mit.edu/hamlet/\nShakespeare, “Macbeth” https://shakespeare.mit.edu/macbeth/\nShakespeare, “Romeo and Juliet” https://shakespeare.mit.edu/romeo_juliet/"
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Penguin Permutation",
    "section": "",
    "text": "I investigate the difference in bill length between male and female penguins from the Palmer Penguins data set. Generally, male penguins are slightly larger than female penguins, but in some species the difference is minimal. I hope to determine if bill length is a good indicator of sex for the species in the data set (Adelie, Gentoo, and Chinstrap). The hypothesis I’m testing is that male penguins have longer bills than females. To do this, I use a permutation test to compare the observed bill length values for male and female penguins with a random distribution.\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\n\n\n\nCode\nview(penguins)\n\n\n\n\nCode\npenguin_data &lt;- penguins %&gt;% \n  filter(!is.na(sex))\npenguin_data %&gt;% \n  ggplot(aes(\n    x = sex, \n    y = bill_length_mm\n  )) +\n  geom_boxplot() +\n  labs(x = \"Sex\", \n       y = NULL, \n       title = \"Bill Length (mm)\")\n\n\n\n\n\n\n\n\n\nAverage bill length for males is slightly higher than females in the observed data.\n\n\nCode\npenguin_data %&gt;% \n  group_by(sex) %&gt;% \n  summarize(avg_bill = mean(bill_length_mm, na.rm = TRUE), \n            med_bill = median(bill_length_mm, na.rm = TRUE)) %&gt;% \n   summarize(avg_diff = diff(avg_bill), \n            med_diff = diff(med_bill))\n\n\n# A tibble: 1 × 2\n  avg_diff med_diff\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     3.76        4\n\n\n\n\nCode\npermutation &lt;- function(n, data){\n  data %&gt;% \n    select(sex, bill_length_mm) %&gt;%\n    filter(!is.na(bill_length_mm)) %&gt;% \n    mutate(bill_perm = sample(bill_length_mm, replace = FALSE)) %&gt;% \n    group_by(sex) %&gt;% \n    summarize(obs_avg = mean(bill_length_mm), \n              obs_med = median(bill_length_mm), \n              perm_avg = mean(bill_perm), \n              perm_med = median(bill_perm)) %&gt;%\n    summarize(obs_avg_diff = diff(obs_avg), \n              obs_med_diff = diff(obs_med), \n              perm_avg_diff = diff(perm_avg), \n              perm_med_diff = diff(perm_med), \n              rep = n)\n}\n\nmap(c(1:5), permutation, data = penguin_data) %&gt;% \n  list_rbind()\n\n\n# A tibble: 5 × 5\n  obs_avg_diff obs_med_diff perm_avg_diff perm_med_diff   rep\n         &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1         3.76            4         0.490          1.20     1\n2         3.76            4         1.22           2.30     2\n3         3.76            4        -0.930         -2.15     3\n4         3.76            4        -0.357          1.55     4\n5         3.76            4        -0.913         -1.75     5\n\n\nThe permutation function creates a “bill_perm” variable, which randomly selects a value from the bill_length_mm column and assigns it a new row. It does this for each row, so that the bill_perm column is randomly swapped bill length values. Then, it groups the rows by sex (male and female, NAs previously removed) and summarizes over the average and median of both the observed data (bill_length_mm) and the random data (bill_perm). Finally, it summarizes again using the diff function to show the difference between the bill_perm average and median between sexes.\n\n\nCode\nset.seed(131)\nperm_data &lt;- \n  map(c(1:500), permutation, data = penguin_data) %&gt;% \n  list_rbind()\n\n\nThe map function inputs a number vector into the permutation function. The function takes the argument n as the number of repetitions, so I map a vector 1:500 into the function to repeat it 500 times with the penguin data to generate 500 average bill length differences between male and female penguins under random chance.\n\n\nCode\nperm_data %&gt;% \n  ggplot(aes(\n    x = perm_avg_diff)) +\n  geom_histogram() + \n  geom_vline(aes(xintercept = obs_avg_diff), color = \"red\") +\n  labs(x = \"Difference in mean\", \n       y = \"Count\")\n\n\n\n\n\n\n\n\n\nThis histograms shows the distribution of the 500 differences between mean bill lengths from the randomly sorted bill length values. The red line is the observed difference in mean bill lengths at 3.76.\n\n\nCode\nperm_data %&gt;% \n  ggplot(aes(\n    x = perm_med_diff)) +\n  geom_histogram() + \n  geom_vline(aes(xintercept = obs_med_diff), color = \"red\") +\n  labs(\n    x = \"Difference in median\", \n    y = \"Count\", \n  )\n\n\n\n\n\n\n\n\n\nThis histogram shows the distribution of differences in medians between male and female from the random sort. The red line is the observed difference in medians of 4.\nAs can be seen in the graphs, p-values for both average difference and median difference are zero. Under the random distribution, the observed differences have a 0% chance to occur.\n\n\nCode\nperm_data %&gt;%  \n  summarize(pvalue_avg = mean(perm_avg_diff &gt; obs_avg_diff),\n            pvalue_med = mean(perm_med_diff &gt; obs_med_diff))\n\n\n# A tibble: 1 × 2\n  pvalue_avg pvalue_med\n       &lt;dbl&gt;      &lt;dbl&gt;\n1          0          0\n\n\nBased on these findings, the observed mean and median differences could not occur if bill length was distributed randomly (regardless of sex). The average male bill length is 3.76 mm greater than the female average, and the median is 4 mm greater. The permutation test shows that this observed difference is significant, and we can reject both null hypotheses for mean and median.\nData:\nHorst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218."
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "Target’s Data Analysis of Pregnancy",
    "section": "",
    "text": "In his 2012 article “How Companies Learn Your Secrets”, NYT writer Charles Duhigg detailed how Target used/uses purchasing data linked to consumer profiles to enhance its marketing techniques. Duhigg referenced a study that found purchases become a rigid habit for consumers, without active decision-making over time. A major life shift, however, can make purchasing habits more flexible in ways that retailers can take advantage of to establish new purchasing habits. In 2002, Target hired statistician Andrew Pole to analyze customers’ purchasing habits. In conversation with Duhigg, Pole explained how he was tasked with developing a model that could predict the likelihood that a customer was pregnant (or preparing to be) based on their purchases. Target assigns each customer a unique ID number linked to their name, credit card, or email address. Each ID holds all the items that person purchased, along with other demographic information Target has gathered (or bought from other sources). Purchasing patterns are collected in accordance with Target’s privacy policy, which indicates that all of a consumer’s “commercial information” may be gathered. This data is collected both in-store and through Target’s website and mobile app.\nPole began gathering data from Target’s baby shower registries, product lists that are publicly available. He tested the data and found that pregnant women tend to buy certain products, such as unscented lotions and soap, specific supplements, and cotton balls. Pole gathered 25 products that could be analyzed together to produce a “pregnancy prediction” score. Additionally, the women using the registry could enter their due date, so Pole was able to match certain products with certain stages of pregnancy. Thus, the purchased/requested products used to generate a pregnancy likelihood could also be used to estimate that woman’s due date. This program was applied to all women who regularly shopped at Target. By tracking those who were likely pregnant, Target could direct advertisements and coupons for baby products, build purchasing habits that would last. From the consumer perspective, there are clear concerns about this marketing practice. Target analyzed women’s purchasing behaviors to make inferences about their personal lives. This analysis was done without the represented individuals’ knowledge to target them for marketing. Regardless of its purpose, using retail data to infer pregnancy and act on those assumptions raises clear ethical concerns. \nConsent Structure\nConsent is a crucial part of protecting the safety and privacy of the people represented by the data. There is no formal consent structure for customers. It is expected that purchasing products at a retailer provides data (what you purchased) linked to an identifier you willingly provide (i.e., credit card or email). The women who were assessed by the pregnancy predictor model did not know that their commercial information would be used in this specific way. Target’s privacy policy declares that this information can be used for “targeted advertising” and research. Beyond this, informed consent for the pregnancy model would not be possible without a direct interaction with each woman who buys something from Target. Thus, giving informed consent to have your purchasing data used in this specific way would be challenging. \nIdentifiable Data\nFor Target’s process, purchasing must be matched with the corresponding customer ID. The goal of analyzing the commercial data is to determine the likelihood of pregnancy and send targeted advertisements. The data is not publicly available, but for Target’s purposes, all of it is identifiable. If a woman buys a certain product, it will be used to predict pregnancy, a result that is matched with her ID indefinitely. \nRespect for Privacy\nAlthough the data is not public, respect for privacy remains questionable. The data itself (what you purchase) is not private, but a customer’s use of purchased products in her personal life should be private. The goal of the predictor model is to make estimates about a woman’s personal life. While the data gathering itself does not infringe on privacy, the model it is used for does so. Sending advertisements based on the outcomes is a key piece of this. Duhigg described one example of a father who was upset his daughter received ads for baby products, only to find out she was pregnant. The ads and coupons represent Target’s assumption/estimate of pregnancy, and regardless of their accuracy, they may have unintended consequences for the woman receiving them. Thus, there are very significant privacy issues with not just Target’s data analysis, but also the resulting targeted marketing strategies. \nEthical implications and Impact on Individuals\nThe unintended consequences on privacy are clear ethical implications that are not significant in Target’s marketing strategy. Target collected and used the data without consideration for the individuals. After some pushback, the targeted ads were diluted with other ads unrelated to pregnancy or child care. This ended up boosting the likelihood that the coupons for baby products would be used. If a woman “believes she hasn’t been spied on, she’ll use the coupons,” said Pole. Clearly, the targeted ads were not received well, which highlights the personal and emotional impact on the women whose personal lives were estimated without their knowledge. \nThe shift in advertising represents the clear, profit-oriented goal of Target’s study. The impact was considered only insofar as it affected customer habits. The goal of the analysis was to manipulate these habits. While the data collection does not violate customer privacy, the potential implications of estimating pregnancy were not considered.  \nSources \nDuhigg, Charles. “How Companies Learn Your Secrets.” The New York Times, Feb. 16, 2012, https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html?unlocked_article_code=1.6U4.nLSt.-yehBjKHEmPW&smid=url-share \nTarget. “Target Privacy Policy.” https://www.target.com/c/target-privacy-policy/-/N-4sr7p"
  },
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "Traffic Stop Analysis",
    "section": "",
    "text": "Code\nlibrary(DBI)\nlibrary(ggplot2)\nlibrary(tidyverse)\ncon_traffic &lt;- DBI::dbConnect(\n\n  RMariaDB::MariaDB(),\n\n  dbname = \"traffic\",\n\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n\nI investigate trends in traffic/pedestrian stop data from my hometown of San Francisco. The first analyses I did was frequency throughout the day. I sought to visualize the trends over the course of the day by grouping by time and plotting each count. The time for each stop was marked with the hour and minute (seconds not specified) for San Francisco, so I grouped by the time variable to count the frequency at each minute in the day.\n\n\nCode\nDESCRIBE ca_san_francisco_2020_04_01;\n\n\n\nDisplaying records 1 - 10\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nraw_row_number\ntext\nYES\n\nNA\n\n\n\ndate\ndate\nYES\n\nNA\n\n\n\ntime\ntime\nYES\n\nNA\n\n\n\nlocation\ntext\nYES\n\nNA\n\n\n\nlat\ndouble\nYES\n\nNA\n\n\n\nlng\ndouble\nYES\n\nNA\n\n\n\ndistrict\ntext\nYES\n\nNA\n\n\n\nsubject_age\nbigint(20)\nYES\n\nNA\n\n\n\nsubject_race\ntext\nYES\n\nNA\n\n\n\nsubject_sex\ntext\nYES\n\nNA\n\n\n\n\n\n\n\n\nCode\nSELECT time, COUNT(*) AS num_stops\nFROM ca_san_francisco_2020_04_01\nGROUP BY time  \n\n\n\n\nCode\ntime_table2 &lt;- time_table %&gt;% \n  filter(!is.na(time)) %&gt;% \n  arrange(time)\n\n\n\n\nCode\ntime_table2 %&gt;% \n  ggplot(aes(x = time, y = num_stops)) +\n  geom_point() +\n  labs(x = \"Time\", \n       y = \"Number of Stops\", \n       title = \"Number of stops throughout day\")\n\n\n\n\n\n\n\n\n\nBased on the plot of counts at each minute, there is an evident discrepency in the time data. Upon observing the data, it is clear that for minute multiples of 5 (and especially 10) the count spikes (i.e. 1:30 much higher than 1:29 and 1:31). This can be viewed in the plot, with consistent low values and regular spikes every 5 minutes. I made the assumption that when an individual traffic stop is recorded, the time of day is often rounded to the nearest regular 5th minute. This is especially clear when observing 10 minute marks, as every 10 minutes after the hour, the count spikes singificantly. To account for the variability of rounding, I chose to only include the count for every 10th minute in my plot.\n\n\nCode\ntime_table5 &lt;- time_table2 %&gt;% \n  filter(minute(time) %in% c(0, 10, 20, 30, 40, 50))\ntime_table5 %&gt;% \n  ggplot(aes(x = time, y = num_stops)) + \n  geom_point() +\n  geom_smooth() +\n  labs(x = \"Time\", \n       y = \"Number of Stops\", \n       title = \"Number of Stops (Every 10th minute)\")\n\n\n\n\n\n\n\n\n\nThere is still some short-term variation and spikes, but it is easier to observe a trend using the geom_smooth line. There is a clear drop in the early morning after 12AM, before the count begins to rise again around 5AM. This is likely when the number of cars on the road starts to increase. The count increases throughout the day, with the slope decreasing gradually after 10AM (before seemingly increasing slightly in the evening).\n\n\nCode\nSELECT time, COUNT(*) AS num_stops, DAYNAME(date) AS wday \nFROM ca_san_francisco_2020_04_01\nGROUP BY time, DAYNAME(date)\nHAVING wday IN (\"Friday\", \"Saturday\", \"Sunday\")\n\n\n\n\nCode\nweekend_table1 &lt;- weekend_table %&gt;% \n  filter(!is.na(time)) %&gt;% \n  filter(!is.na(wday)) %&gt;% \n  filter(minute(time) %in% c(0, 30))\nweekend_table1 %&gt;% \n  ggplot(aes(x = time, y = num_stops, color = wday)) + \n  geom_point() +\n  geom_smooth() +\n  labs(x = \"Time\", \n       y = \"Number of Stops\", \n       title = \"Number of Stops (Every 30th minute)\")\n\n\n\n\n\n\n\n\n\nIn this graph I isolate the data from Fridays, Saturdays and Sundays. To simplify the plot and reduce additional data collection variability, I filter for the stops only from either on the hour or half past. It seems that Friday has a higher number of stops from around 4AM to after 8PM. Sunday has significantly fewer stops in the evening, with the difference only growing later into the night. Interestingly, the positions at the end of the plot are vastly different than the beginning of the plot, though I’m not sure of a possible explaination.\nI was also curious to analyze traffic stop data based on race for young adults. To make additional comparison, I added the data set from Oakland. I filtered the data to include just the stops where the subject was under 25 years old.\n\n\nCode\nSELECT subject_race, COUNT(*) AS num_stops, \"San Francisco\" AS city \nFROM ca_san_francisco_2020_04_01\nWHERE subject_age &lt; 25\nGROUP BY subject_race\n\nUNION \n\nSELECT subject_race, COUNT(*) AS num_stops, \"Oakland\" AS city \nFROM ca_oakland_2020_04_01\nWHERE subject_age &lt; 25\nGROUP BY subject_race\n\nORDER BY num_stops DESC \n\n\n\n\nCode\ntable3 %&gt;% \n  group_by(subject_race) \n\n\n# A tibble: 10 × 3\n# Groups:   subject_race [5]\n   subject_race           num_stops city         \n   &lt;chr&gt;                    &lt;int64&gt; &lt;chr&gt;        \n 1 white                      47476 San Francisco\n 2 black                      33496 San Francisco\n 3 asian/pacific islander     25468 San Francisco\n 4 hispanic                   24410 San Francisco\n 5 other                      16435 San Francisco\n 6 black                       5967 Oakland      \n 7 hispanic                    2945 Oakland      \n 8 asian/pacific islander       371 Oakland      \n 9 white                        368 Oakland      \n10 other                        324 Oakland      \n\n\nCode\ntable3 %&gt;% \n  group_by(city) %&gt;% \n  summarize(sum(num_stops))\n\n\n# A tibble: 2 × 2\n  city          `sum(num_stops)`\n  &lt;chr&gt;                  &lt;int64&gt;\n1 Oakland                   9975\n2 San Francisco           147285\n\n\nIn the 25 and under data for both cities, Black young adults are disproportionately the subjects of traffic/pedestrian stops. They made up 22% of stops in San Francisco despite making up only 5-6% of the city’s population, and over half of stops in Oakland despite making up only 20% of the population. In Oakland, the white population makes up about a quarter of the city, but only 4% of young adults stopped in Oakland were white.\nReferences\nE. Pierson, C. Simoiu, J. Overgoor, S. Corbett-Davies, D. Jenson, A. Shoemaker, V. Ramachandran, P. Barghouty, C. Phillips, R. Shroff, and S. Goel. “A large-scale analysis of racial disparities in police stops across the United States”. Nature Human Behaviour, Vol. 4, 2020."
  },
  {
    "objectID": "DSPres.html#data",
    "href": "DSPres.html#data",
    "title": "Water Insecurity in the US",
    "section": "Data",
    "text": "Data\nTidy Tuesday Water Insecurity Data - Observation at county level measured by percent of households lacking plumbing\n\nhead(water_insecurity_data)\n\n# A tibble: 6 × 4\n  name                            total_pop plumbing percent_lacking_plumbing\n  &lt;chr&gt;                               &lt;dbl&gt;    &lt;dbl&gt;                    &lt;dbl&gt;\n1 Baldwin County, Alabama            253507      271                   0.107 \n2 Houston County, Alabama            108462       30                   0.0277\n3 Los Angeles County, California    9663345     5248                   0.0543\n4 Santa Cruz County, California      261547      187                   0.0715\n5 Sonoma County, California          481812      308                   0.0639\n6 Contra Costa County, California   1155025      517                   0.0448"
  },
  {
    "objectID": "DSPres.html#regional-analysis",
    "href": "DSPres.html#regional-analysis",
    "title": "Water Insecurity in the US",
    "section": "Regional Analysis",
    "text": "Regional Analysis\nCreating regions (West example)\n\nwest &lt;- c(\"Arizona\",\"Colorado\",\"Idaho\",\"Montana\",\"Nevada\",\"New Mexico\",\"Utah\",\"Wyoming\",\n               \"Alaska\",\"California\",\"Hawaii\",\"Oregon\",\"Washington\")\n\nCreating separate “state” and “county” variables and assigning rows to region\n\nwater_insecurity_2023 &lt;- mutate(water_insecurity_2023,\n    state = str_extract(name, \"(?&lt;=, ).*\"), \n    county = str_extract(name, \".*(?=,)\")\n  )\nwater_insecurity_2023 &lt;-  mutate(water_insecurity_2023,\n    region = case_when(\n      state %in% northeast ~ \"Northeast\",\n      state %in% midwest ~ \"Midwest\",\n      state %in% south ~ \"South\",\n      state %in% west ~ \"West\",\n      ))"
  },
  {
    "objectID": "DSPres.html#regional-plot",
    "href": "DSPres.html#regional-plot",
    "title": "Water Insecurity in the US",
    "section": "Regional Plot",
    "text": "Regional Plot\n\n\nCode\n\n\nggplot(state_avg23,\n  aes(x=region, \n      y=avg_perc, \n      color = region)) +\ngeom_jitter(width = .2, \n            size=3.5, \n            alpha = .8, \n            show.legend = FALSE) +\ngeom_text_repel(data = outliers, \n                aes(label = state), \n                color = \"black\") +\nlabs(x=\"Region\",\n     y=\"Percentage Lacking Plumbing (State Mean)\",\n     title=\"Percentage Lacking Plumbing 2023 \"\n)"
  },
  {
    "objectID": "DSPres.html#examining-the-outliers",
    "href": "DSPres.html#examining-the-outliers",
    "title": "Water Insecurity in the US",
    "section": "Examining The Outliers",
    "text": "Examining The Outliers\n\n\nCode\n\n\nggplot(state_outliers, aes(x = log(total_pop), \n                   y = percent_lacking_plumbing, \n                   color = state)) +\n  geom_point(size = 3, \n             alpha = .7) +\n  geom_smooth(method = \"lm\", \n              color = \"black\") +\n  geom_text_repel(data = county_outliers, \n                  aes(label = county), \n                  color = \"black\") +\n  labs(x = \"log(Population)\", \n       y = \"Percent Lacking Plumbing\", \n       title = \"Water Insecurity and Population (AK, AZ, & NM)\") +\n  theme_minimal()"
  },
  {
    "objectID": "DSPres.html#examining-relationship-with-indigenous-populations",
    "href": "DSPres.html#examining-relationship-with-indigenous-populations",
    "title": "Water Insecurity in the US",
    "section": "Examining relationship with indigenous populations",
    "text": "Examining relationship with indigenous populations\nUploaded 2023 county-level data from census.gov\n\ncensus_data &lt;- census_data %&gt;% \n  select(STNAME, CTYNAME, TOT_POP, YEAR, IA_MALE, IA_FEMALE, AGEGRP) %&gt;% \n  mutate(IA_TOT = IA_MALE + IA_FEMALE, \n         IA_prop = (IA_MALE + IA_FEMALE)/TOT_POP) %&gt;% \n  filter(YEAR == 5, AGEGRP == 0) %&gt;% \n  rename(county = CTYNAME)\n\nJoined census data with water insecurity data by county name\n\nmerged_data &lt;- census_data %&gt;% \n  left_join(water_insecurity_2023, by = \"county\")"
  },
  {
    "objectID": "DSPres.html#plotting-the-relationship",
    "href": "DSPres.html#plotting-the-relationship",
    "title": "Water Insecurity in the US",
    "section": "Plotting the relationship",
    "text": "Plotting the relationship\n\n\nCode\n\n\nggplot(clean_data, \n       aes(x = IA_prop, \n           y = percent_lacking_plumbing)) +\n  geom_point(alpha = 0.7, \n             color = \"steelblue2\") +\n  geom_smooth(method = \"lm\", \n              color = \"black\") +\n  geom_text_repel(data = plumbing_outliers, \n                  label = plumbing_outliers$county) +\n  labs(x = \"Native American Prop of County Population\", \n       y = \"Percent Lacking Plumbing\", \n       title = \"Relationship Between Indigenous Population Share and Water Insecurity\") +\n  theme_minimal()"
  },
  {
    "objectID": "DSPres.html#sources",
    "href": "DSPres.html#sources",
    "title": "Water Insecurity in the US",
    "section": "Sources",
    "text": "Sources\nAzadpour, Elmera and Nell, Cee, 2024, “Mapping water insecurity in R with tidycensus,” USGS,https://waterdata.usgs.gov/blog/acs-maps/\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-01-28 USGS - https://waterdata.usgs.gov/blog/acs-maps/\nU.S. Census Bureau, 2023, “Tenure by Plumbing Facilities,” American Community Survey, 1-Year Estimates Detailed Tables, Table B25049, accessed on Nov 27, 2024, https://data.census.gov/table?q=B25049&y=2023 .\nU.S. Census Bureau, 2023, “Total Population,” American Community Survey, 1-Year Estimates Detailed Tables, Table B01003, accessed on Nov 27, 2024, https://data.census.gov/table?q=B01003&y=2023 .\nU.S. Census Bureau, 2025, “County Population by Characteristics: 2020-2024”, Annual County Resident Population Estimates by Age, Sex, Race, and Hispanic Origin: April 1, 2020 to July 1, 2024, accessed on Dec 2, 2025, https://www.census.gov/data/tables/time-series/demo/popest/2020s-counties-detail.html"
  }
]